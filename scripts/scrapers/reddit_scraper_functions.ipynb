{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit scraper\n",
    "## Author: Karina Lopez\n",
    "### Last updated: 06/09/2021\n",
    "\n",
    "**Purpose:** Scrape specified subreddit based on specific search terms; Returns datasets with post information and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your token key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these instructions to get your token key: https://towardsdatascience.com/scraping-reddit-data-1c0af3040768\n",
    "\n",
    "at this site: https://www.reddit.com/prefs/apps\n",
    "\n",
    "- **client id:** (personal use script)\n",
    "- **secret:** \n",
    "- **user_agent:** (name)\n",
    "- **redirect URI:** http://localhost:8080\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = '',\n",
    "                     client_secret = '',\n",
    "                     user_agent = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter your variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### top n subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### FUNCTION VARIABLES #######\n",
    "\n",
    "# Base directory string\n",
    "BASE_DIR = '/Users/karinalopez/Desktop/ds_projects/nlp/'\n",
    "\n",
    "# subreddit_name: name of the subreddit you would like to scrape\n",
    "subreddit_name_ = 'femalefashionadvice'\n",
    "\n",
    "# num_posts: number of posts you would like to scrape\n",
    "num_posts_ = 10000\n",
    "\n",
    "# fname: name of your new CSV data file\n",
    "fname_ = 'top10000_ffa_subreddit_posts.csv'\n",
    "\n",
    "# folder_dir: Directory where your destination CSV file should be stored\n",
    "folder_dir_ = 'data/raw/ffa_sustainability/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query search subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORY: Directory where your destination CSV file should be stored\n",
    "DIRECTORY_ = '/Users/karinalopez/Desktop/ds_projects/nlp/data/raw/ffa_sustainability/sustainable'\n",
    "\n",
    "# query: key words you would like to search in each subreddit\n",
    "query_ = ['ethics', \n",
    "          'sustainable', \n",
    "          'activism', \n",
    "          'ethical consumption', \n",
    "          'microplastics', \n",
    "          'ethical', \n",
    "          'greenwashing',\n",
    "          'pure',\n",
    "          'natural',\n",
    "          'earth-friendly',\n",
    "          'eco-friendly',\n",
    "          'organic',\n",
    "          'reduced emissions',\n",
    "          'sustainable development', \n",
    "          'carbon-neutral',\n",
    "          'plant-based']\n",
    "\n",
    "# sub: list of subreddits you would like to scrape\n",
    "sub_ = ['femalefashionadvice']\n",
    "\n",
    "# posts fname\n",
    "posts_fname = 'MEGA_ffa_posts_sustainability.csv'\n",
    "\n",
    "# commments fname\n",
    "comments_fname = 'MEGA_ffa_comments_sustainability.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape top n posts on specified subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_posts(subreddit_name, num_posts, fname, folder_dir):\n",
    "    \n",
    "    hot_posts = reddit.subreddit(subreddit_name).hot(limit = num_posts)\n",
    "    \n",
    "    \n",
    "    # save your dataset into a pandas dataframe\n",
    "\n",
    "    posts = []\n",
    "\n",
    "    subreddit_instance = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    for post in subreddit_instance.hot(limit = num_posts):\n",
    "        posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "\n",
    "    posts = pd.DataFrame(posts, columns = ['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "\n",
    "    posts.head(n = 10)\n",
    "    \n",
    "    # save your dataframe\n",
    "    os.chdir(BASE_DIR + folder_dir)\n",
    "    posts.to_csv(fname, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_posts(subreddit_name_, num_posts_, fname_, folder_dir_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword comment scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(DIRECTORY, query, sub = ['femalefashionadvice']):\n",
    "    \n",
    "    os.chdir(DIRECTORY)\n",
    "    \n",
    "    # initiate your empty dataframes\n",
    "    comments_list = []\n",
    "    posts_list = []\n",
    "    \n",
    "    \n",
    "    for s in sub:\n",
    "\n",
    "        subreddit = reddit.subreddit(s)   # Chosing the subreddit\n",
    "\n",
    "\n",
    "    ########################################\n",
    "    #   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "    ########################################\n",
    "\n",
    "    #   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "    #   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "    #   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "    # SCRAPING CAN BE DONE VIA VARIOUS STRATEGIES {HOT,TOP,etc} we will go with keyword strategy i.e using search a keyword\n",
    "        #query = ['women', 'ethics']\n",
    "\n",
    "        for item in query:\n",
    "\n",
    "            # Create empty dictionaries\n",
    "            post_dict = {\n",
    "                \"title\" : [],   #title of the post\n",
    "                \"score\" : [],   # score of the post\n",
    "                \"id\" : [],      # unique id of the post\n",
    "                \"url\" : [],     #url of the post\n",
    "                \"comms_num\": [],   #the number of comments on the post\n",
    "                \"created\" : [],  #timestamp of the post\n",
    "                \"body\" : []         # the descriptionof post\n",
    "            }\n",
    "\n",
    "            comments_dict = {\n",
    "                \"comment_id\" : [],      #unique comm id\n",
    "                \"comment_parent_id\" : [],  # comment parent id\n",
    "                \"comment_body\" : [],   # text in comment\n",
    "                \"comment_link_id\" : []  #link to the comment\n",
    "            }\n",
    "\n",
    "\n",
    "            for submission in subreddit.search(item, sort = \"top\", limit = 100):\n",
    "\n",
    "                post_dict[\"title\"].append(submission.title)\n",
    "                post_dict[\"score\"].append(submission.score)\n",
    "                post_dict[\"id\"].append(submission.id)\n",
    "                post_dict[\"url\"].append(submission.url)\n",
    "                post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "                post_dict[\"created\"].append(submission.created_utc)\n",
    "                post_dict[\"body\"].append(submission.name)\n",
    "\n",
    "                ##### Acessing comments on the post\n",
    "                submission.comments.replace_more(limit = None)\n",
    "\n",
    "                for comment in submission.comments.list():\n",
    "                    comments_dict[\"comment_id\"].append(comment.id)\n",
    "                    comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "                    comments_dict[\"comment_body\"].append(comment.body)\n",
    "                    comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "\n",
    "            # Create your comment datasets\n",
    "            post_comments = pd.DataFrame(comments_dict)\n",
    "            post_comments['keyword'] = item\n",
    "            \n",
    "            # Add to a list of dataframes\n",
    "            comments_list.append(post_comments)\n",
    "            post_comments.to_csv(\"comments_\" + s + \"_\" + item + \".csv\", index = False)\n",
    "            \n",
    "            # Create your post datasets\n",
    "            post_data = pd.DataFrame(post_dict)\n",
    "            post_data['keyword'] = item\n",
    "            \n",
    "            # Add to a list of dataframes\n",
    "            posts_list.append(post_data)\n",
    "            post_data.to_csv('posts_' + s + \"_\" + item + \".csv\", index = False)\n",
    "            \n",
    "    \n",
    "    return(posts_list, comments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerError",
     "evalue": "received 503 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-160152582c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIRECTORY_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-394db96b47ea>\u001b[0m in \u001b[0;36mscrape_comments\u001b[0;34m(DIRECTORY, query, sub)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m##### Acessing comments on the post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_more\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/models/comment_forest.py\u001b[0m in \u001b[0;36mreplace_more\u001b[0;34m(self, limit, threshold)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/models/reddit/more.py\u001b[0m in \u001b[0;36mcomments\u001b[0;34m(self, update)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;34m\"sort\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment_sort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             }\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_PATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"morechildren\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, data, files, params, json)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             return self._objectify_request(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36m_objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \"\"\"\n\u001b[1;32m    665\u001b[0m         return self._objector.objectify(\n\u001b[0;32m--> 666\u001b[0;31m             self.request(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, params, data, files, json)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mClientException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At most one of `data` and `json` is supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             return self._core.request(\n\u001b[0m\u001b[1;32m    849\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"api_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         return self._request_with_retries(\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETRY_STATUSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         ):\n\u001b[0;32m--> 247\u001b[0;31m             return self._do_retry(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_do_retry\u001b[0;34m(self, data, files, json, method, params, response, retry_strategy_state, saved_exception, timeout, url)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retrying due to {status} status: {method} {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return self._request_with_retries(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETRY_STATUSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         ):\n\u001b[0;32m--> 247\u001b[0;31m             return self._do_retry(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_do_retry\u001b[0;34m(self, data, files, json, method, params, response, retry_strategy_state, saved_exception, timeout, url)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Retrying due to {status} status: {method} {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return self._request_with_retries(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    258\u001b[0m             )\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_EXCEPTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"no_content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerError\u001b[0m: received 503 HTTP response"
     ]
    }
   ],
   "source": [
    "posts, comments = scrape_comments(DIRECTORY_, query_, sub_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DIRECTORY_)\n",
    "posts.to_csv(posts_fname, index = False)\n",
    "comments.to_csv(comments_fname, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
